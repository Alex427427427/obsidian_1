**Conductor**: Alexander Li, student ID 30630711, contactable via alii0024@student.monash.edu
**Date**: 2024 August 6
# Risk Assessment
![[risk assessment.png]]
# Aim
To perform spatial filtering of images with the Fourier optical functions of a lens, and observe how the image is affected. 
# 1 Background Theory
There are multiple ways to derive Fourier optics. In the following I choose the approach most natural to me - integration of wavelets. 
##### 1.1 Principles of Fourier Optics
The local mechanism of light propagation can be modelled as spherical waves emerging from infinitesimal point sources everywhere in space, forming wavefronts by superposition. This is Hyugen's principle. Since the development of electromagnetic theory, the physical mechanism of light propagation in materials was finally derived, and indeed found to be consistent with Hyugen's principle. Every location in a medium acts as an infinitesimal local oscillator, polarising and magnetising as previous wavefronts pass through, generating their own spherical wavelets to form the next wavefront. (**Source: 2016, Hecht E, Optics, Chapter 3.5 - Light in Bulk Matter**)

Fourier optics is the mathematically rigorous application of this idea. The resultant wave amplitude at some detection location, is a sum of spherical waves of the form $e^{ikr}/r$ over a spatial distribution of all sources. We shall carry this analysis through to see the Fourier transform emerge. 

Suppose there is a plane on which the amount of light that is let through depends on some spatial **aperture function** $A(x)$. (For example, a hard slit would be 1 for the range of $x$ values where there is no barrier, and 0 everywhere else. 1 indicating that all incident light is let through, 0 indicating no incident light is let through.) 
![[fourier optics expl 1.png]]
Then Hyugen's principle states that the wave amplitude $\Psi$ at some location $z$ away from the slit and $x$ off the optical axis would be: 
$$\Psi(z,x)\propto\int_{-\infty}^{\infty}A(x^\prime)\frac{e^{ikr}}{r}dx^\prime$$
Which, when the geometry has been expressed explicitly in terms of $z$ and $x$, becomes:
$$\Psi(z,x)\propto\int_{-\infty}^\infty A(x^\prime)\frac{e^{ik\sqrt{z^2+(x-x^\prime)^2}}}{\sqrt{z^2+(x-x^\prime)^2}}dx^\prime$$
This is the integral that gives the exact wave amplitude. 
##### 1.2 Fresnel Approximation
The intermediate field, or **Fresnel zone**, is a region where the **para-axial approximation** is valid. In other words, $z\gg x$, $z\approx r$, and using the binomial approximation, the wave amplitude simplifies to: 
$$\Psi(z,x)\propto\frac{e^{ikz}}{z}\int_{-\infty}^\infty A(x^\prime)e^{ik(x-x^\prime)^2/2z}dx^\prime$$
Which is the **Fresnel integral**. 
##### 1.3 Far Field Approximation
We can yet simplify the equation more in the far field, which begins at the Fraunhofer distance $d_F$:
$$\boxed{d_F=2\frac{W^2}{\lambda}}$$
where $W$ is the maximum dimension of the radiating element. (**Source: 1982, Balanis C, Antenna Theory, Chapter 2.2.4 Field Regions**)

Physically, this corresponds to where we are so far that any tiny angular deviation from the optical axis results in a huge displacement $x$, compared to the original total dimension of the aperture function. In other words, $x\gg x^\prime$, which, when the Fresnel integral is evaluated to first order with this in mind, gives: 
$$\boxed{\Psi(z,x)\propto\frac{e^{ikz}}{z}e^{ik_xx/2}\int_{-\infty}^\infty A(x^\prime)e^{-ik_xx^\prime}dx^\prime}$$
This is the **Fraunhofer integral**, and where the form of the Fourier transform emerges. Note that $k_x:=kx/r\approx kx/z$. The terms outside the integral do not affect the intensity along $x$ at a fixed $z$, so we can say that **the intensity pattern $|\Psi|^2$ is proportional to the square of the Fourier transform of the aperture function**. In 2 dimensions: 
$$\boxed{\Psi(z,x,y)\propto\frac{e^{ikz}}{z}e^{i(k_xx+k_yy)/2}\iint_{Aperture} A(x^\prime,y^\prime)e^{-i(k_xx^\prime+k_yy^\prime)}dx^\prime dy^\prime}$$
More properties of this equation for the wave amplitude distribution will be discussed later when appropriate. 
##### 1.4 Application to Images and Lenses
A monochromatic image is really just equivalent to some spatial aperture function. As spherical light propagates away from every point on the image into the far field region, the intensity distribution over a wavefront eventually becomes the square of the Fourier transform of the image. 

Now imagine instead of letting light propagate all the way into the far field region, we insert a lens at one focal length away. Since the lens turns points on the focal plane into plane waves on the other side, it's as if we skipped all the propagation straight into the far field region where rays are parallel to one another - we went straight to the Fourier transform. The reverse is true - incoming plane waves (which by now are in the far field relative to the source) get focused to a point on the focal plane of the lens to create an image, which makes the process an inverse Fourier transform. 

By feeding the light from an image through a lens placed at one focal length away, we can directly manipulate the Fourier transform of the image, and use another lens further along to inverse Fourier transform, resulting in the altered image at a focal length away from this second lens. 
# 2 Preparatory Questions
##### 2.1 Fraunhofer Pattern
![[prep q1.png]]
- The near field transforms into the far field as explained in the previous section, $2D^2/\lambda$
- Both the Fresnel near field pattern and the Fraunhofer far field pattern are created by interference between various angular components of the wave. 
- But in the near field case, the interference never completely destroys the intensity at a particular spot, because the angular variation of rays that combine at a particular spot is still high enough for light from certain components to hit places that would otherwise be destructively interfered by other components. Geometrically we see this as rays of different angles hitting the same spot. 
- By the time we reach the far field, the angular distribution have completely resolved, leaving the rays to neatly march onward without further change in the pattern. By this region, the rays that hit a particular spot are basically parallel, and total destructive interference can occur. 
##### 2.2 Image at Fourier Plane
![[prep q2.png]]
- We would see a radial distribution that looks like the square of $sinc(\rho)$, for that is the Fourier transform of $rect(\rho)$, which is what a circular aperture is. The angular distribution should be uniform, for the aperture was rotationally symmetric. 
- The mathematical formalism that relates the aperture and the screen is the Fourier transform. 
##### 2.3 Diffraction Maxima
![[prep q3.png]]
- The $m$th maximum on the screen must correspond to the path difference of rays from each element to be $m$ full cycles from one another, so that they maximally constructively interfere. 
- In the limit of far field, the rays are parallel to one another. Thus there is a single expression of path difference that is valid for all those parallel rays: 
$$d\sin(\theta)=m\lambda$$
- In the small angle approximation, $\sin(\theta)\approx\theta$. Rearranging for $\theta$ gives:
$$\boxed{\theta=\frac{m\lambda}{d}}$$
# 3 Log of the Experiment
##### 3.1 Initial Set Up
- On top of a rail, I set up a green laser at one end. And, in order from one end of the rail to the other: a grating which produces a grid image, a lens at roughly one focal length away from the grating, a filter at roughly one focal length away from the lens, and a mirror at the other end. The focal length is taken to be the label on the lens for now - 250mm. The mirror helps increase the total propagation of the laser by two fold, because the camera (hidden behind a scattering screen) is placed next to the laser, facing the mirror - this allows us to perform inverse Fourier transform due to the propagation into the far field. 
![[setup 1.png]]
![[setup 2.png|200]]
##### 3.2 Camera Configuration
- Realising I didn't need the filter yet, I took it off the rail. 
- I connected the camera to my laptop via USB, and started ThorCAM to view the image. I confirmed the image matches what i see on the scattering screen. 
![[first image.png|200]]
- I noticed the image shown on software is rotated by 90 degrees compared to the physical set up upon wiggling the camera. There is no software setting for rotation and no mechanical equipment to change the orientation of the camera about the roll axis, so I keep this in mind for the rest of the experiment. 
- I adjusted the exposure for the camera until the image was not too bright. 
- I calibrated the scale of the camera by aiming it at a white background (the ceiling), placing a short ruler on top of it, and capturing an image. 
![[calibration image.png|200]]
- In an image processing software ImageJ, I found that a straight line connecting markers 5cm apart corresponds to 1109 pixels - which gives the scale:
$$scale=\frac{1109\ pixels}{50\ mm}\approx 22.18\ pixels/mm$$
- Noticing that my measurement on the screen can be off by around 5 pixels, I found that the uncertainty in the scale is 0.1 pixels/mm. Thus the scale is:
$$\boxed{scale=22.2\pm0.1\ pixels/mm}$$
##### 3.3 Determining the Focal Length of the Lens
- I then determined the focal length of the lens in practice. 
- I fixed the grating (image) at the 25.00cm marking on the rail, the far mirror at 200cm, and the camera's scattering screen at 1cm. I moved the lens around until the image on the scattering screen became sharp. The lens had to sit at 52.20cm.  
- This meant the object distance was 27.20cm. 
- I just noticed that the actual locations of the grating and the lens do not line up with the markings on the rail. Rotating them by 180 degrees in their mount fixed this issue. 
- With the correction, the lens had to be moved to 52.00cm. Which means the object distance is 27.00cm. 
- Since the distance from the lens to the mirror is 148.00cm, and the distance from the mirror to the camera scattering screen is 199cm, the image distance is 347cm. 
- With the thin lens formula $1/f=1/d_o+1/d_i$, I rearranged for $f$, and found that:
$$f_1=\frac{d_id_o}{d_i+d_o}\approx 25.05cm$$
- I put the calculations into a python file. Assuming the alignment of the camera next to the rail has an uncertainty of 1cm, and that the rail markings have 0.01cm uncertainty, propagating the uncertainty to the focal length via quadrature gives an uncertainty of $0.14cm$. Keeping 1 significant figure of the uncertainty, I arrive at: 
$$\boxed{f_1=25.1\pm0.1cm}$$
- I repeated the same procedure for lens 2, and found its focal length to be: 
$$\boxed{f_2 = 15.2\pm0.1cm}$$
##### 3.4 Measuring Bar Period of the Grid
- I returned the set up to lens 1, chose the medium sized grids at the first aperture, and adjusted the position of lens 1 until the image of the grid was clear on the scattering screen of the camera. Since the lens was at 51.88cm, the object distance must be $51.88 - 25.00 = 26.88cm$, and the image distance is $199 + (200-51.88) = 347.12cm$. This corresponds to a thin lens magnification of: 
$$M=\frac{d_i}{d_o}\approx12.91$$
- Propagating the uncertainties (taken to be the same as argued above, I obtained:
$$\boxed{M=12.91\pm0.04}$$
- So I proceeded to save the image and measure the grid period in pixels. To avoid the uncertainty in the gridline thickness, I took measurement from a corner to another corner. To further reduce uncertainty, i took measurement over 8 grids. It was 586 pixels. 
- I measured 8 grids at another location on the image, and got 584 pixels. Taking the average, I got 585 pixels, with an uncertainty of 1 pixel. 
- Using the scale and propagating uncertainties, I calculated the grid width $w_i$ of the image to be: 
$$w_i=\frac{585/8}{scale}=3.29\pm0.02\ mm$$
- Using the magnification and propagating uncertainties, I calculated the actual grid width $w_o$ of the object to be:
$$\boxed{w_o=\frac{w_i}{M}=0.255\pm0.001\ mm}$$
##### 3.5 Estimating Near Field - Far Field Transition
- I removed the lens, and held a white paper to receive the light passing through the grid object. I moved the white paper further and further away from the grid, and observed the patterns. 
- At close to the grid, I saw the Fresnel diffraction pattern - where individual lobes were present, but overlap and are not fully resolved. 
![[FT 1.png|200]]
- Moving beyond the 50cm marking on the rails, I saw the lobes become distinct, and proper dark bands to appear, separating the lobes. This is the Fraunhofer diffraction pattern. 
![[FT 2.png|200]]
- However, as I moved even further, I realised that *each of the individual lobes* contained many smaller sub-lobes, which were still overlapping to form the larger lobes previously observed. 
![[FT3.png|200]]
- As I traced the image all the way to the camera, I saw that those sub-lobes were beginning to separate and become independent, but they still were infringing on one another. 
![[FT4.png|200]]
![[sub lobes.png|200]]
- I compared these results to the theoretical prediction - that the far field begins at $2W^2/\lambda$. Where $W$ is the maximum dimension of the radiating element, and $\lambda = 531.7\pm0.5\ nm$ which was the wavelength of the laser. Taking $W=9w_o$ because the total diameter of the object was 9 grids, I found the far field should begin at $$z=2\frac{W^2}{\lambda}\approx20\ m$$
- This obvious did not match the original location of 50cm where the lobes began to resolve, which was a distance of 25cm away from the object. 
- However, if we take the width $W$ to be a *single grid*, which was a dominant spatially periodic feature of the object, then we get: 
$$z=2\frac{w_o^2}{\lambda}\approx 24\ cm$$
- So the full picture is: as we reach beyond 24cm, one dominant spatial periodic mode becomes resolved in the pattern as large lobes - the one associated with the grids themselves. As we move further, the total dimension of the grid object becomes resolved in the pattern as small sub-lobes for each large lobe. If we were able to capture the whole image at beyond 20m, we should have been able to see these sub-lobes to be completely separated, and we will have obtained the complete Fourier transform of the original object. 
- To confirm the above, I emulated a full far-field propagation by placing lens_1 at 1 focal length away from the grid object, and placing the camera at the Fourier plane on the other side of the lens. I placed a ruler at the original location of the camera so I could return the camera to it later. 
- By adjusting the exposure, I saw that the pattern was indeed one where every large lobe had a sea of smaller cleanly resolved lobes accompanying each. 
![[FT grid low exp.png|200]]
![[FT grid high exp.png|200]]
##### 3.6 Measuring the Diffraction Pattern
- With the camera still on the rail, I removed the lens, and measured the diffraction pattern in pixels at distances with 20cm increments. This is for the medium sized grids. 

**Table 1: Distance vs Lobe width of the Diffraction Pattern** 

| camera distance from object (cm) | Lobe width (pixels) |
| -------------------------------- | ------------------- |
| $60\pm1$                         | $162\pm2$           |
| $80\pm1$                         | $223\pm5$           |
| $100\pm1$                        | $269\pm8$           |
| $120\pm1$                        | $331\pm7$           |
- I will perform a fit and find out the width of the original grid in later sections. 
##### 3.7 Spatial Filtering with Slit
- I placed the camera back at the ruler marking. I placed lens 1 at a location such that the image appears sharp at the camera screen. So lens 1 was at the 51.88cm marking on the rails. 
- I placed a slit filter at about one focal length away from the lens, and adjusted the mount until the slit is centered at the center of the Fourier pattern. 
- For various grid sizes, I recorded the images of various amounts of filtering. 

**Table 2: Various vertical filtering of various grid sizes**

| grid size | large vertical slit         | medium vertical slit        | miniscule vertical slit     |
| --------- | --------------------------- | --------------------------- | --------------------------- |
| fine      | ![[fine vert 1.png\|100]]   | ![[fine vert 2.png\|100]]   | ![[fine vert 3.png\|100]]   |
| medium    | ![[med vert 1.png\|100]]    | ![[med vert 2.png\|100]]    | ![[med vert 3.png\|100]]    |
| coarse    | ![[coarse vert 1.png\|100]] | ![[coarse vert 2.png\|100]] | ![[coarse vert 3.png\|100]] |
- **Note that these images should be rotated by 90 degrees.** 
- So we see that the **horizontal features** get more and more smeared out as we reduce the width of the vertical slit. The vertical features are unaffected. This is because filtering is only done to the horizontal spatial frequencies. 
- Another observation: smaller grid sizes correspond to sparser Fourier transforms, which makes sense because small grid size means higher spatial frequency. As a result, it is easier to pinch the fourier transform of smaller grid sizes, because the lobes are more sparse and can be discretely filtered. 
- I repeated the above procedure for horizontal slits. Since the minimum height of the horizontal slit was still to high, I had to adjust every element in the apparatus to be slightly higher. 

| grid size | large horizontal slit       | medium horizontal slit      | miniscule horizontal slit   |
| --------- | --------------------------- | --------------------------- | --------------------------- |
| fine      | ![[fine hori 1.png\|100]]   | ![[fine hori 2.png\|100]]   | ![[fine hori 3.png\|100]]   |
| medium    | ![[med hori 1.png\|100]]    | ![[med hori 2.png\|100]]    | ![[med hori 3.png\|100]]    |
| coarse    | ![[coarse hori 1.png\|100]] | ![[coarse hori 2.png\|100]] | ![[coarse hori 3.png\|100]] |
- Again, **the actual images formed are rotated by 90 degrees**. 
- So we see that the **vertical features** get smeared out, due to the killing of higher spatial frequencies in the vertical direction by the horizontal slit. The horizontal features are unaffected.
##### 3.8 Iris Aperture 
- I replaced the slit filter with the iris filter, aligning the center of the iris with the center of the beam. 
- I recorded the medium grids at various closings of the iris aperture. 

| ![[iris 1.png\|100]] | ![[iris 2.png\|100]] | ![[iris 3.png\|100]] | ![[iris 4.png\|100]] | ![[iris 5.png\|100]] |
| -------------------- | -------------------- | -------------------- | -------------------- | -------------------- |
- I see that the image becomes more and more blurred circularly, as if a gaussian blurring filter is being applied to the image. Of course, we know that the actual filter is a sharp circle, but at a certain limit, the circle allows exactly one gaussian beam to pass through. 
- I then probed the effect of linearly increasing the aperture size, allowing integer number of spots on the Fourier plane to pass through. 

| lobes | 1                         | 2                         | 3                         | 4                         |
| ----- | ------------------------- | ------------------------- | ------------------------- | ------------------------- |
| image | ![[iris lobe 1.png\|100]] | ![[iris lobe 2.png\|100]] | ![[iris lobe 3.png\|100]] | ![[iris lobe 4.png\|100]] |
| lobes | 5                         | 6                         | 7                         | fully open                |
| image | ![[iris lobe 5.png\|100]] | ![[iris lobe 6.png\|100]] | ![[iris lobe 7.png\|100]] | ![[iris lobe 8.png\|100]] |
- The gridlines become clearer and clearer, and more square. By order 5, even miniscule interference artefacts are not really noticeable. 
- We see that starting from order 5, the image has no noticeable difference to when the iris is fully open. 
##### 3.9 Central Spot
- I replaced the iris aperture with a glass slide containing a dark spot, blocking out the center of the Fourier-transformed beam. 
![[central spot removed.png|200]]
- I see that the flat regions are suppressed and the edges become highlighted. From the Fourier point of view, we have just removed the component that corresponds to the average intensity of the image, leaving behind only the components that have non zero spatial frequency and thus have some spatial change - it makes me wonder, whether this could work as an edge detector in computer vision pipelines. 
##### 3.10 Wrap Up
- With all aspects of the experiment explored, I shut down the laser, camera, and returned the various optical elements to their stand. 
# Further Analysis
This section is the continuation of 3.6 Measuring the Diffraction Pattern. 
# Discussion

# Conclusion

# References
Located throughout the logbook. 